<h1 align="center">Awesome-MLLM-Inference</h3>

<div align="center">

[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)
![Static Badge](https://img.shields.io/badge/Status-Maintaining-%23ecfc03)
![Static Badge](https://img.shields.io/badge/PRs-Welcome-%23fc2003)
![Static Badge](https://img.shields.io/badge/License-MIT-%23e0ebdf)



</div>

### Contents
- [Awesome-MLLM-Inference](#awesome-mllm-inference)
   - [MLLM Survey](#mllm-survey)
   - [Pruning](#pruning)
   - [Quantization](#quantization)
   - [Mlsys](#mlsys)
   - [Distillation](#distillation)
   - [Long Context](#long-context)


#### MLLM Survey

- [Efficient Multimodal Large Language Models: A Survey](https://arxiv.org/abs/2405.10739)
- [A Survey on Multimodal Large Language Models]()
- [A Survey on Efficient Inference for Large Language Models]()
- [Natural Language Understanding and Inference with MLLM in Visual Question Answering: A Survey](https://arxiv.org/pdf/2411.17558)
- [A survey of Mixture of Experts in Multi-Modal Large Language Models]()
- [Efficient Multimodal Learning from Data-centric Perspective]()


#### Pruning
- [Fast and training-free visual token pruning for multi-modal large language models]()
- [freePruner: A Training-free Approach for Large Multimodal Model Acceleration](https://arxiv.org/abs/2411.15446)
- [Turbo: Informativity-Driven Acceleration Plug-In for Vision-Language Large Models]()
- [AIM: Adaptive Inference of Multi-Modal LLMs via Token Merging and Pruning]()
- [LLaVA-PruMerge: Adaptive Token Reduction for Efficient Large Multimodal Models]()
- [Treat Visual Tokens as Text? But Your MLLM Only Needs Fewer Efforts to See]()
- [SmartTrim: Adaptive Tokens and Attention Pruning for Efficient Vision-Language Models](https://arxiv.org/abs/2305.15033)
- [FoPru: Focal Pruning for Efficient Large Vision-Language Models](https://arxiv.org/abs/2411.14164)
- [Multimodal Alignment-Guided Dynamic Token Pruning for Accelerating Vision-Language Transformer]()


#### Quantization
- [MQuant: Unleashing the Inference Potential of Multimodal Large Language Models via Full Static Quantization]()
- [Advancing Multimodal Large Language Models with Quantization-Aware Scale Learning for Efficient Adaptation]()



#### Distillation
- [LLaVA-MoD: Making LLaVA Tiny via MoE Knowledge Distillation]()
- [LLaVA-KD: A Framework of Distilling Multimodal Large Language Models]()


#### Mlsys
- [SparseVLM: Visual Token Sparsification for Efficient Vision-Language Model Inference]()


#### Long Context
- [Inf-MLLM: Efficient Streaming Inference of Multimodal Large Language Models on a Single GPU](https://arxiv.org/abs/2409.09086)

#### Others
- [Mini-Monkey: Multi-Scale Adaptive Cropping for Multimodal Large Language Models]()
- [Efficient Large Multi-modal Models via Visual Context Compression]()
- [TokenPacker: Efficient Visual Projector for Multimodal LLM]()
- [PyramidDrop: Accelerating Your Large Vision-Language Models via Pyramid Visual Redundancy Reduction]()
- [Accelerating Multimodal Large Language Models by Searching Optimal Vision Token Reduction](https://arxiv.org/abs/2412.00556)
- [FlashSloth: Lightning Multimodal Large Language Models via Embedded Visual Compression](https://arxiv.org/abs/2412.04317)
- [Rethinking Token Reduction in MLLMs: Towards a Unified Paradigm for Training-Free Acceleration](https://arxiv.org/abs/2411.17686)
