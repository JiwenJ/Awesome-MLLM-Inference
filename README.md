

<h1 align="center">Awesome-MLLM-Inference</h3>

<div align="center">

[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)
![Static Badge](https://img.shields.io/badge/Status-Maintaining-%23ecfc03)
![Static Badge](https://img.shields.io/badge/PRs-Welcome-%23fc2003)
![Static Badge](https://img.shields.io/badge/License-MIT-%23e0ebdf)



</div>



## Contents
- [Awesome-MLLM-Inference](#awesome-mllm-inference)
   - [Survey](#survey)
   - [Pruning](#pruning)
   - [Quantization](#quantization)
   - [Mlsys](#mlsys)
   - [Distillation](#distillation)
   - [Long Context](#long-context)


### Survey

- [Efficient Multimodal Large Language Models: A Survey](https://arxiv.org/abs/2405.10739)


#### Pruning
- [freePruner: A Training-free Approach for Large Multimodal Model Acceleration](https://arxiv.org/abs/2411.15446)


#### Quantization



#### Distillation


#### Mlsys


#### Long Context
- [Inf-MLLM: Efficient Streaming Inference of Multimodal Large Language Models on a Single GPU](https://arxiv.org/abs/2409.09086)
